\chapter{Future Work}
\paragraph{}
The project work completed as part of Stage 1 of the project has resulted in significant insights into the impact of parameters such as vehicle velocity and the prediction \& control horizon on the behaviour of model predictive controllers. We have successfully implemented basic and adaptive controllers for two different driving tasks, namely trajectory tracking and obstacle avoidance. However, a significant amount of work remains to be done, which will be tackled in the next stage of the project. This includes, but is not limited to:
\begin{itemize}
    \item \textbf{Use of adaptive MPC for trajectory tracking around a racetrack}

    The model discussed in section 4.1.3 was locked to a specific pre-set value of vehicle velocity. This significantly hampered the response of the controller, since we were unable to adjust the vehicle's speed. A possible improvement to this model would be the inclusion of an adaptive MPC controller instead of a basic MPC controller, so that the vehicle states can be fed back to the controller to allow for adjustment of velocity as the vehicle turns along the track.
    \item \textbf{Employing non-linear MPC models}

    The continuous-time vehicle dynamics model is a non-linear one. Up till now, we have only looked at implementations of linear model predictive controllers, which required discretization to convert the non-linear model into a linear one that can be passed as an input to the controller. Though the output responses observed so far have been satisfactory, employing a non-linear MPC controller to be able to handle the continuous-time model without any need for discretization. This could potentially lead to performance improvements and better output responses.

    A major part of the future plan involves the exploration of non-linear MPC to incorporate a spatial bicycle model instead of the simple bicycle model we have been using so far. This will preclude the requirement of discretization, providing a more accurate tracking response. It will also allow for use of more complex tire models such as the Dugoff and Pacejka tire models for more precise computation of vehicle dynamics. 
    \item \textbf{Inclusion of image processing algorithms for obstacle detection}

    The obstacle avoidance algorithms discussed in sections 4.1.4 and 4.2 have relied on user-instantiated obstacles. While this is a convenient and less computationally expensive way of assessing the accuracy of a model, obstacles encountered by cars in the real world may not necessarily be pre-determined (e.g., landslides, construction work, etc). To account for this aspect of real-life obstacles, it is important to incorporate input from image sensors, such as cameras, LIDAR and SONAR sensors, in order to effectively locate any obstacles in the operational design domain of the ego vehicle. 
    
    With some additional processing, the sensor outputs can be converted into the obstacle's relative coordinates that can be used to generate obstacle constraints dynamically. The relevant models discussed section 4 can then be employed for the path planning task.

    \item \textbf{Inclusion of other actors in the self-driving environment}
    
    The simulations discussed in this report have included only the ego vehicle and obstacles, if any. We have not accounted for the presence of other actors in the self-driving environment, such as other vehicles and pedestrians. Hence, the models have been much less complex relative to an actual self-driving task. The inclusion of other actors in the surrounding environment would pose additional challenges for the optimal control problem. However, this would also provide a more accurate measure of how the controller would behave in the real world.

    This will be another major point of focus in the next stage of the project. 2-dimensional top-down simulations or 3-dimensional simulation will be carried out in open-source simulators, such as CARLA or Udacity's self-driving simulator, to demonstrate the effects of real-world driving aspects on MPC controller performance, including but not limited to traffic lights, pedestrian crossings and other vehicle actors in the operational design domain of the ego vehicle.

    \item \textbf{Implementation of reinforcement learning models for the path planning task}

    An alternative approach instead of employing a traditional feedback control system is the use of reinforcement learning algorithms for self-driving tasks. This would mean that the current system framework would be retired, in favour of a neural network that runs a reward-based optimization algorithm for controlling the vehicle. The training of such a type of self-driving algorithm is likely to take a significant amount of time, but it will reduce the number of post-training computations required. A reinforcement learning framework also means that the model learns from its earlier actions, which, in turn, would result in a generally superior ability to predict, follow and respond faster to previously encountered environmental changes as well as drastically reduce the number of repeated errors.
\end{itemize}

\noindent The possibilities mentioned above will be tackled as part of the project's next stage. Of course, this list is not exhaustive, and there may be other methods/improvements that may be discovered over the course of the project.